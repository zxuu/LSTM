{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这是pad操作，sequences也是list。这个比较好理解，就是给list里的tensor都用padding_value来pad成最长的长度，并组合成一个tensor：\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "a = torch.ones(3,8)\n",
    "b = torch.ones(4,8)\n",
    "c = torch.ones(5,8)\n",
    "pad_sequence([a,b,c], batch_first=False, padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([1, 4, 6, 2, 5, 3]), batch_sizes=tensor([3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这是pack操作，输入的sequences是tensor组成的list，要求按长度从大到小排序。官网的例子：\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_sequence\n",
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([4,5])\n",
    "c = torch.tensor([6])\n",
    "pack_sequence([a,b,c])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 其他两个常用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = t.tensor([[1,2,3],[6,0,0],[4,5,0]]) #(batch_size, max_length)\n",
    "lengths = t.tensor([3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 2, 1]) tensor([0, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# 排序\n",
    "a_lengths, idx = lengths.sort(0, descending=True)\n",
    "print(a_lengths, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 0],\n",
      "        [6, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "_, un_idx = t.sort(idx, dim=0)\n",
    "a = a[idx]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1765, -1.0014],\n",
       "         [ 0.7083, -0.0463],\n",
       "         [-0.2064, -0.6541]],\n",
       "\n",
       "        [[-2.4080,  0.3991],\n",
       "         [ 0.5537, -0.2426],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.1955, -0.5838],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = t.nn.Embedding(20, 2, padding_idx=0)    # 第一行全为0.\n",
    "lstm = t.nn.LSTM(input_size=2, hidden_size=4, batch_first=True)\n",
    "a_input = emb(a)\n",
    "a_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.1765, -1.0014],\n",
       "        [-2.4080,  0.3991],\n",
       "        [ 0.1955, -0.5838],\n",
       "        [ 0.7083, -0.0463],\n",
       "        [ 0.5537, -0.2426],\n",
       "        [-0.2064, -0.6541]], grad_fn=<PackPaddedSequenceBackward0>), batch_sizes=tensor([3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_packed_input = t.nn.utils.rnn.pack_padded_sequence(input=a_input, lengths=a_lengths, batch_first=True)\n",
    "a_packed_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.1765, -1.0014],\n",
       "        [ 0.7083, -0.0463],\n",
       "        [-0.2064, -0.6541],\n",
       "        [-2.4080,  0.3991],\n",
       "        [ 0.5537, -0.2426],\n",
       "        [ 0.1955, -0.5838]], grad_fn=<PackPaddedSequenceBackward0>), batch_sizes=tensor([3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_packed_input2 = t.nn.utils.rnn.pack_padded_sequence(input=a_input, lengths=a_lengths) # batch_first=false\n",
    "a_packed_input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.0748,  0.0699,  0.1413, -0.1009],\n",
       "        [-0.1208,  0.1010,  0.4545,  0.2097],\n",
       "        [-0.0854,  0.1046,  0.1260, -0.0984],\n",
       "        [-0.1234,  0.1776,  0.1904, -0.1299],\n",
       "        [-0.0959,  0.1811,  0.3077,  0.0080],\n",
       "        [-0.1293,  0.2048,  0.3234, -0.1136]], grad_fn=<CatBackward0>), batch_sizes=tensor([3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_out, _ = lstm(a_packed_input)\n",
    "packed_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0748,  0.0699,  0.1413, -0.1009],\n",
       "         [-0.1208,  0.1010,  0.4545,  0.2097],\n",
       "         [-0.0854,  0.1046,  0.1260, -0.0984]],\n",
       "\n",
       "        [[-0.1234,  0.1776,  0.1904, -0.1299],\n",
       "         [-0.0959,  0.1811,  0.3077,  0.0080],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.1293,  0.2048,  0.3234, -0.1136],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, _ = pad_packed_sequence(packed_out)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0748,  0.0699,  0.1413, -0.1009],\n",
       "         [-0.1208,  0.1010,  0.4545,  0.2097],\n",
       "         [-0.0854,  0.1046,  0.1260, -0.0984]],\n",
       "\n",
       "        [[-0.1293,  0.2048,  0.3234, -0.1136],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.1234,  0.1776,  0.1904, -0.1299],\n",
       "         [-0.0959,  0.1811,  0.3077,  0.0080],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n",
       "       grad_fn=<IndexSelectBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = t.index_select(out, 0, un_idx)\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tor1131py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
